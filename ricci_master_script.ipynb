{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Ricci Flow Layer Depth Study - Master Script\n",
                "## Training + Live Ricci Analysis (Combined)\n",
                "\n",
                "This notebook combines:\n",
                "- DNN training for varying layer depths (3-30)\n",
                "- **Live Ricci curvature analysis** immediately after training each model\n",
                "- Results saved incrementally to Google Drive\n",
                "\n",
                "**Implements all paper metrics:**\n",
                "- Forman-Ricci curvature: R(i,j) = 4 - deg(i) - deg(j)\n",
                "- Geodesic mass: g_l = Σ γ_l(i,j)\n",
                "- Aggregated Ricci coefficient (Rho)\n",
                "\n",
                "**Based on:** `training.py`, `knn_fixed.py`, and \"Deep Learning as Ricci Flow\" (Baptista et al., 2024)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Mount Google Drive"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# GOOGLE DRIVE MOUNT & PATH SETUP (Crucial for persistent storage)\n",
                "# ============================================================================\n",
                "from google.colab import drive\n",
                "import os\n",
                "\n",
                "# Mount Google Drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Set output directory to Drive\n",
                "OUTPUT_DIR = '/content/drive/MyDrive/ricci_study_combined'\n",
                "\n",
                "if not os.path.exists(OUTPUT_DIR):\n",
                "    os.makedirs(OUTPUT_DIR)\n",
                "    print(f\"✓ Created output directory: {OUTPUT_DIR}\")\n",
                "else:\n",
                "    print(f\"✓ Output directory exists: {OUTPUT_DIR}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Imports & GPU Detection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# IMPORTS\n",
                "# ============================================================================\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import os\n",
                "import time\n",
                "from tqdm.auto import tqdm\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# TensorFlow/Keras\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense\n",
                "from tensorflow.keras.optimizers import RMSprop\n",
                "from tensorflow.keras.datasets import mnist\n",
                "\n",
                "# Ricci Analysis\n",
                "from sklearn.neighbors import NearestNeighbors\n",
                "from scipy.sparse import csr_matrix, triu as sp_triu\n",
                "from scipy.sparse.csgraph import shortest_path\n",
                "from scipy.stats import pearsonr, spearmanr\n",
                "from typing import List, Dict, Tuple\n",
                "\n",
                "# Visualization\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# ============================================================================\n",
                "# GPU DETECTION\n",
                "# ============================================================================\n",
                "print(\"=\" * 60)\n",
                "print(\"DEVICE DETECTION\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "gpus = tf.config.list_physical_devices('GPU')\n",
                "if gpus:\n",
                "    print(f\"✓ GPU(s) detected: {len(gpus)}\")\n",
                "    for gpu in gpus:\n",
                "        print(f\"  - {gpu.name}\")\n",
                "    try:\n",
                "        for gpu in gpus:\n",
                "            tf.config.experimental.set_memory_growth(gpu, True)\n",
                "        print(\"✓ GPU memory growth enabled\")\n",
                "    except RuntimeError as e:\n",
                "        print(f\"⚠ GPU memory growth setting failed: {e}\")\n",
                "else:\n",
                "    print(\"⚠ No GPU detected. Training will use CPU.\")\n",
                "    print(\"  Tip: Enable GPU in Kaggle/Colab settings for faster training.\")\n",
                "\n",
                "print(f\"\\nTensorFlow version: {tf.__version__}\")\n",
                "print(\"=\" * 60)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# CONFIGURATION\n",
                "# ============================================================================\n",
                "\n",
                "# Binary classification digits\n",
                "DIGIT_A = 4\n",
                "DIGIT_B = 9\n",
                "\n",
                "# Layer depths to test (3 to 30)\n",
                "LAYER_DEPTHS = list(range(3, 31))\n",
                "\n",
                "# Architecture configurations\n",
                "ARCHITECTURES = {\n",
                "    'narrow': {'width': 25, 'bottleneck': False},\n",
                "    'wide': {'width': 50, 'bottleneck': False},\n",
                "    'bottleneck': {'width': 50, 'bottleneck': True}\n",
                "}\n",
                "\n",
                "# Training parameters\n",
                "NUM_MODELS = 25       # Models per configuration\n",
                "EPOCHS = 50\n",
                "BATCH_SIZE = 32\n",
                "EARLY_STOP_ACCURACY = 0.99\n",
                "\n",
                "# Ricci Analysis parameters\n",
                "K_VALUE = 200         # ~10% of test samples for kNN\n",
                "ACC_THRESHOLD = 0.0   # Use all models (set higher to filter)\n",
                "\n",
                "# Output files\n",
                "RESULTS_CSV = os.path.join(OUTPUT_DIR, 'ricci_combined_results.csv')\n",
                "\n",
                "print(\"Configuration:\")\n",
                "print(f\"  Digits: {DIGIT_A} vs {DIGIT_B}\")\n",
                "print(f\"  Layer Depths: {LAYER_DEPTHS[0]}-{LAYER_DEPTHS[-1]}\")\n",
                "print(f\"  Architectures: {list(ARCHITECTURES.keys())}\")\n",
                "print(f\"  Models per config: {NUM_MODELS}\")\n",
                "print(f\"  k for kNN: {K_VALUE}\")\n",
                "print(f\"  Total configurations: {len(ARCHITECTURES) * len(LAYER_DEPTHS)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Load MNIST Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# DATA LOADING\n",
                "# ============================================================================\n",
                "\n",
                "print(\"Loading MNIST data...\")\n",
                "(x_train_full, y_train_full), (x_test_full, y_test_full) = mnist.load_data()\n",
                "\n",
                "# Filter for binary classification\n",
                "train_mask = (y_train_full == DIGIT_A) | (y_train_full == DIGIT_B)\n",
                "test_mask = (y_test_full == DIGIT_A) | (y_test_full == DIGIT_B)\n",
                "\n",
                "x_train = x_train_full[train_mask].reshape(-1, 784).astype('float32') / 255.0\n",
                "x_test = x_test_full[test_mask].reshape(-1, 784).astype('float32') / 255.0\n",
                "y_train = (y_train_full[train_mask] == DIGIT_B).astype('int32')\n",
                "y_test = (y_test_full[test_mask] == DIGIT_B).astype('int32')\n",
                "\n",
                "print(f\"\\nDataset loaded:\")\n",
                "print(f\"  Training samples: {x_train.shape[0]}\")\n",
                "print(f\"  Test samples: {x_test.shape[0]}\")\n",
                "print(f\"  Feature dimension: {x_train.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# MODEL ARCHITECTURE & TRAINING\n",
                "# ============================================================================\n",
                "\n",
                "class StopAt99(tf.keras.callbacks.Callback):\n",
                "    \"\"\"Stop training when accuracy reaches 99%.\"\"\"\n",
                "    def on_epoch_end(self, epoch, logs=None):\n",
                "        if logs.get('accuracy', 0) >= EARLY_STOP_ACCURACY:\n",
                "            self.model.stop_training = True\n",
                "\n",
                "\n",
                "def build_model(arch_config: Dict, depth: int, input_dim: int = 784) -> Sequential:\n",
                "    \"\"\"Build DNN model based on architecture configuration.\"\"\"\n",
                "    model = Sequential()\n",
                "    width = arch_config['width']\n",
                "    is_bottleneck = arch_config['bottleneck']\n",
                "    \n",
                "    # First hidden layer\n",
                "    first_width = 50 if is_bottleneck else width\n",
                "    model.add(Dense(first_width, activation='relu', input_shape=(input_dim,)))\n",
                "    \n",
                "    # Remaining hidden layers\n",
                "    hidden_width = 25 if is_bottleneck else width\n",
                "    for _ in range(depth - 1):\n",
                "        model.add(Dense(hidden_width, activation='relu'))\n",
                "    \n",
                "    # Output layer\n",
                "    model.add(Dense(1, activation='sigmoid'))\n",
                "    \n",
                "    model.compile(\n",
                "        loss='binary_crossentropy',\n",
                "        optimizer=RMSprop(),\n",
                "        metrics=['accuracy']\n",
                "    )\n",
                "    \n",
                "    return model\n",
                "\n",
                "print(\"✓ Model architecture functions defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. kNN Graph Building Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# kNN GRAPH BUILDING (from knn_fixed.py)\n",
                "# ============================================================================\n",
                "\n",
                "def build_knn_graph(X: np.ndarray, k: int) -> csr_matrix:\n",
                "    \"\"\"\n",
                "    Return an undirected, unweighted kNN adjacency in CSR format.\n",
                "    Symmetrize by max and set diagonal to 0.\n",
                "    \"\"\"\n",
                "    if X.ndim == 1:\n",
                "        X = X.reshape(-1, 1)\n",
                "    if X.dtype != np.float32 and X.dtype != np.float64:\n",
                "        X = X.astype(np.float32, copy=False)\n",
                "    \n",
                "    knn = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
                "    knn.fit(X)\n",
                "    A = knn.kneighbors_graph(X, mode='connectivity')\n",
                "    \n",
                "    # Symmetrize (undirected graph)\n",
                "    A = A.maximum(A.T)\n",
                "    \n",
                "    # Zero-out diagonal (no self-loops)\n",
                "    A.setdiag(0)\n",
                "    A.eliminate_zeros()\n",
                "    \n",
                "    return A.tocsr()\n",
                "\n",
                "print(\"✓ build_knn_graph() defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Geodesic Mass & Forman-Ricci"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# GEODESIC MASS (Paper Eq. 7)\n",
                "# g_l = sum_{i<j} gamma_l(i, j)\n",
                "# ============================================================================\n",
                "\n",
                "def sum_shortest_paths(A: csr_matrix) -> float:\n",
                "    \"\"\"\n",
                "    Compute geodesic mass g = sum of all-pairs shortest-path distances (i < j).\n",
                "    \"\"\"\n",
                "    dist = shortest_path(A, directed=False, unweighted=True)\n",
                "    iu = np.triu_indices_from(dist, k=1)\n",
                "    vals = dist[iu]\n",
                "    \n",
                "    # Handle disconnected components\n",
                "    finite = np.isfinite(vals)\n",
                "    if not np.all(finite):\n",
                "        vals = vals[finite]\n",
                "    \n",
                "    return float(vals.sum())\n",
                "\n",
                "\n",
                "# ============================================================================\n",
                "# FORMAN-RICCI CURVATURE (Paper Eq. 4, 6)\n",
                "# R(i, j) = 4 - deg(i) - deg(j)\n",
                "# Ric_l = sum_{(i,j) in E_l} R_l(i, j)\n",
                "# ============================================================================\n",
                "\n",
                "def global_forman_ricci(A: csr_matrix) -> float:\n",
                "    \"\"\"\n",
                "    Compute global Forman-Ricci curvature coefficient.\n",
                "    \"\"\"\n",
                "    deg = np.asarray(A.sum(axis=1)).ravel()\n",
                "    A_ut = sp_triu(A, k=1).tocoo()\n",
                "    curv = 4.0 - deg[A_ut.row] - deg[A_ut.col]\n",
                "    return float(curv.sum())\n",
                "\n",
                "print(\"✓ sum_shortest_paths() defined\")\n",
                "print(\"✓ global_forman_ricci() defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Aggregated Ricci Coefficient (Rho)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# AGGREGATED RICCI COEFFICIENT (Rho)\n",
                "# Computes mean Ricci curvature across all layers for a model\n",
                "# ============================================================================\n",
                "\n",
                "def compute_aggregated_ricci(activations: List[np.ndarray], X0: np.ndarray, k: int) -> float:\n",
                "    \"\"\"\n",
                "    Compute the aggregated Ricci coefficient (rho) for a single model.\n",
                "    \n",
                "    From the paper (Eq. 10):\n",
                "        Ric = (1 / (L-1)) * sum_{l=1}^{L-1} Ric_l\n",
                "    \n",
                "    This is the mean Ricci curvature across all layers, used to\n",
                "    correlate with model accuracy.\n",
                "    \"\"\"\n",
                "    # Baseline graph on input space (l=0)\n",
                "    A0 = build_knn_graph(X0, k)\n",
                "    Ric0 = global_forman_ricci(A0)\n",
                "    ric_list = [Ric0]\n",
                "    \n",
                "    # Hidden layers\n",
                "    for Xl in activations:\n",
                "        A = build_knn_graph(np.asarray(Xl), k)\n",
                "        ric_list.append(global_forman_ricci(A))\n",
                "    \n",
                "    # Mean Ricci across all layers\n",
                "    return float(np.mean(ric_list))\n",
                "\n",
                "print(\"✓ compute_aggregated_ricci() defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Main Training + Live Analysis Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# MAIN TRAINING + LIVE ANALYSIS LOOP\n",
                "# ============================================================================\n",
                "\n",
                "def train_and_analyze_one_config(arch_name: str, depth: int):\n",
                "    \"\"\"\n",
                "    Train models and immediately perform Ricci analysis.\n",
                "    Results are saved incrementally to CSV.\n",
                "    \"\"\"\n",
                "    arch_config = ARCHITECTURES[arch_name]\n",
                "    \n",
                "    # Check if already done\n",
                "    if os.path.exists(RESULTS_CSV):\n",
                "        existing_df = pd.read_csv(RESULTS_CSV)\n",
                "        if len(existing_df[(existing_df['architecture'] == arch_name) & (existing_df['depth'] == depth)]) > 0:\n",
                "            print(f\"  [SKIP] {arch_name}/depth_{depth} already in CSV\")\n",
                "            return\n",
                "    \n",
                "    # Storage\n",
                "    accuracy_list = []\n",
                "    rho_list = []\n",
                "    \n",
                "    # Train and analyze each model\n",
                "    for j in range(NUM_MODELS):\n",
                "        # Build and train model\n",
                "        model = build_model(arch_config, depth)\n",
                "        model.fit(\n",
                "            x_train, y_train,\n",
                "            epochs=EPOCHS,\n",
                "            batch_size=BATCH_SIZE,\n",
                "            validation_split=0.2,\n",
                "            callbacks=[StopAt99()],\n",
                "            verbose=0\n",
                "        )\n",
                "        \n",
                "        # Evaluate\n",
                "        _, acc = model.evaluate(x_test, y_test, verbose=0)\n",
                "        accuracy_list.append(acc)\n",
                "        \n",
                "        # Extract activations from hidden layers\n",
                "        activations = []\n",
                "        inp = x_test\n",
                "        for layer in model.layers[:-1]:  # Exclude output layer\n",
                "            inp = layer(inp).numpy()\n",
                "            activations.append(inp)\n",
                "        \n",
                "        # Compute Aggregated Ricci (Rho) immediately\n",
                "        rho = compute_aggregated_ricci(activations, x_test, K_VALUE)\n",
                "        rho_list.append(rho)\n",
                "        \n",
                "        # Clear memory\n",
                "        del model\n",
                "        tf.keras.backend.clear_session()\n",
                "    \n",
                "    # Create result row\n",
                "    result = {\n",
                "        'architecture': arch_name,\n",
                "        'depth': depth,\n",
                "        'k': K_VALUE,\n",
                "        'mean_accuracy': np.mean(accuracy_list),\n",
                "        'std_accuracy': np.std(accuracy_list),\n",
                "        'mean_rho': np.mean(rho_list),\n",
                "        'std_rho': np.std(rho_list),\n",
                "        'n_models': NUM_MODELS\n",
                "    }\n",
                "    \n",
                "    # Save incrementally (append mode)\n",
                "    result_df = pd.DataFrame([result])\n",
                "    result_df.to_csv(\n",
                "        RESULTS_CSV,\n",
                "        mode='a',\n",
                "        header=not os.path.exists(RESULTS_CSV),\n",
                "        index=False\n",
                "    )\n",
                "    \n",
                "    print(f\"  ✓ {arch_name}/depth_{depth}: acc={result['mean_accuracy']:.4f}±{result['std_accuracy']:.4f}, \"\n",
                "          f\"rho={result['mean_rho']:.2e}±{result['std_rho']:.2e}\")\n",
                "\n",
                "print(\"✓ train_and_analyze_one_config() defined\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Run Training + Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# RUN TRAINING + LIVE ANALYSIS\n",
                "# ============================================================================\n",
                "\n",
                "print(\"=\" * 80)\n",
                "print(\"TRAINING + LIVE RICCI ANALYSIS\")\n",
                "print(f\"Total configurations: {len(ARCHITECTURES) * len(LAYER_DEPTHS)}\")\n",
                "print(f\"Models per configuration: {NUM_MODELS}\")\n",
                "print(f\"Results will be saved to: {RESULTS_CSV}\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "start_time = time.time()\n",
                "\n",
                "for arch_name in ARCHITECTURES.keys():\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"ARCHITECTURE: {arch_name.upper()}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    for depth in tqdm(LAYER_DEPTHS, desc=f\"{arch_name} depths\"):\n",
                "        train_and_analyze_one_config(arch_name, depth)\n",
                "\n",
                "total_time = time.time() - start_time\n",
                "\n",
                "print(f\"\\n{'='*80}\")\n",
                "print(f\"COMPLETE!\")\n",
                "print(f\"Total time: {total_time/60:.1f} minutes\")\n",
                "print(f\"Results saved to: {RESULTS_CSV}\")\n",
                "print(f\"{'='*80}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. View Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# VIEW RESULTS\n",
                "# ============================================================================\n",
                "\n",
                "if os.path.exists(RESULTS_CSV):\n",
                "    results_df = pd.read_csv(RESULTS_CSV)\n",
                "    print(\"Results Summary:\")\n",
                "    print(results_df.to_string(index=False))\n",
                "else:\n",
                "    print(\"No results file found. Run training first.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Visualization: Accuracy vs Depth"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# VISUALIZATION: ACCURACY VS DEPTH\n",
                "# ============================================================================\n",
                "\n",
                "if os.path.exists(RESULTS_CSV):\n",
                "    results_df = pd.read_csv(RESULTS_CSV)\n",
                "    \n",
                "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
                "    \n",
                "    for arch_name in ARCHITECTURES.keys():\n",
                "        arch_data = results_df[results_df['architecture'] == arch_name].sort_values('depth')\n",
                "        if len(arch_data) > 0:\n",
                "            ax.errorbar(\n",
                "                arch_data['depth'],\n",
                "                arch_data['mean_accuracy'],\n",
                "                yerr=arch_data['std_accuracy'],\n",
                "                label=arch_name,\n",
                "                marker='o',\n",
                "                capsize=3\n",
                "            )\n",
                "    \n",
                "    ax.set_xlabel('Number of Hidden Layers (Depth)', fontsize=12)\n",
                "    ax.set_ylabel('Test Accuracy', fontsize=12)\n",
                "    ax.set_title(f'MNIST {DIGIT_A} vs {DIGIT_B}: Accuracy vs Layer Depth', fontsize=14)\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(os.path.join(OUTPUT_DIR, 'accuracy_vs_depth.png'), dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"\\n✓ Plot saved to: {OUTPUT_DIR}/accuracy_vs_depth.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Visualization: Rho vs Depth"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# VISUALIZATION: RHO VS DEPTH\n",
                "# ============================================================================\n",
                "\n",
                "if os.path.exists(RESULTS_CSV):\n",
                "    results_df = pd.read_csv(RESULTS_CSV)\n",
                "    \n",
                "    fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
                "    \n",
                "    for arch_name in ARCHITECTURES.keys():\n",
                "        arch_data = results_df[results_df['architecture'] == arch_name].sort_values('depth')\n",
                "        if len(arch_data) > 0:\n",
                "            ax.errorbar(\n",
                "                arch_data['depth'],\n",
                "                arch_data['mean_rho'],\n",
                "                yerr=arch_data['std_rho'],\n",
                "                label=arch_name,\n",
                "                marker='o',\n",
                "                capsize=3\n",
                "            )\n",
                "    \n",
                "    ax.set_xlabel('Number of Hidden Layers (Depth)', fontsize=12)\n",
                "    ax.set_ylabel('Aggregated Ricci Coefficient (ρ)', fontsize=12)\n",
                "    ax.set_title(f'MNIST {DIGIT_A} vs {DIGIT_B}: Ricci Curvature vs Layer Depth', fontsize=14)\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(os.path.join(OUTPUT_DIR, 'rho_vs_depth.png'), dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"\\n✓ Plot saved to: {OUTPUT_DIR}/rho_vs_depth.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14. Visualization: Accuracy vs Rho Correlation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# VISUALIZATION: ACCURACY VS RHO CORRELATION\n",
                "# ============================================================================\n",
                "\n",
                "if os.path.exists(RESULTS_CSV):\n",
                "    results_df = pd.read_csv(RESULTS_CSV)\n",
                "    \n",
                "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
                "    \n",
                "    colors = {'narrow': 'blue', 'wide': 'green', 'bottleneck': 'red'}\n",
                "    \n",
                "    for arch_name in ARCHITECTURES.keys():\n",
                "        arch_data = results_df[results_df['architecture'] == arch_name]\n",
                "        if len(arch_data) > 0:\n",
                "            ax.scatter(\n",
                "                arch_data['mean_rho'],\n",
                "                arch_data['mean_accuracy'],\n",
                "                label=arch_name,\n",
                "                color=colors.get(arch_name, 'gray'),\n",
                "                alpha=0.7,\n",
                "                s=50\n",
                "            )\n",
                "    \n",
                "    # Compute Spearman correlation\n",
                "    if len(results_df) > 2:\n",
                "        rho_corr, p_val = spearmanr(results_df['mean_rho'], results_df['mean_accuracy'])\n",
                "        ax.set_title(f'Accuracy vs Aggregated Ricci Coefficient\\nSpearman ρ = {rho_corr:.3f}, p = {p_val:.2e}', fontsize=14)\n",
                "    else:\n",
                "        ax.set_title('Accuracy vs Aggregated Ricci Coefficient', fontsize=14)\n",
                "    \n",
                "    ax.set_xlabel('Aggregated Ricci Coefficient (ρ)', fontsize=12)\n",
                "    ax.set_ylabel('Test Accuracy', fontsize=12)\n",
                "    ax.legend()\n",
                "    ax.grid(True, alpha=0.3)\n",
                "    \n",
                "    plt.tight_layout()\n",
                "    plt.savefig(os.path.join(OUTPUT_DIR, 'accuracy_vs_rho.png'), dpi=150, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    \n",
                "    print(f\"\\n✓ Plot saved to: {OUTPUT_DIR}/accuracy_vs_rho.png\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 15. Summary Statistics"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ============================================================================\n",
                "# SUMMARY STATISTICS\n",
                "# ============================================================================\n",
                "\n",
                "if os.path.exists(RESULTS_CSV):\n",
                "    results_df = pd.read_csv(RESULTS_CSV)\n",
                "    \n",
                "    print(\"=\" * 60)\n",
                "    print(\"SUMMARY STATISTICS\")\n",
                "    print(\"=\" * 60)\n",
                "    \n",
                "    for arch_name in ARCHITECTURES.keys():\n",
                "        arch_data = results_df[results_df['architecture'] == arch_name]\n",
                "        if len(arch_data) > 0:\n",
                "            print(f\"\\n{arch_name.upper()}:\")\n",
                "            print(f\"  Configurations: {len(arch_data)}\")\n",
                "            print(f\"  Best accuracy: {arch_data['mean_accuracy'].max():.4f} at depth {arch_data.loc[arch_data['mean_accuracy'].idxmax(), 'depth']}\")\n",
                "            print(f\"  Worst accuracy: {arch_data['mean_accuracy'].min():.4f} at depth {arch_data.loc[arch_data['mean_accuracy'].idxmin(), 'depth']}\")\n",
                "            print(f\"  Rho range: [{arch_data['mean_rho'].min():.2e}, {arch_data['mean_rho'].max():.2e}]\")\n",
                "    \n",
                "    # Overall correlation\n",
                "    if len(results_df) > 2:\n",
                "        rho_corr, p_val = spearmanr(results_df['mean_rho'], results_df['mean_accuracy'])\n",
                "        print(f\"\\n{'='*60}\")\n",
                "        print(f\"OVERALL SPEARMAN CORRELATION (Accuracy vs Rho):\")\n",
                "        print(f\"  ρ = {rho_corr:.4f}, p-value = {p_val:.2e}\")\n",
                "        print(f\"{'='*60}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        },
        "colab": {
            "provenance": []
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}